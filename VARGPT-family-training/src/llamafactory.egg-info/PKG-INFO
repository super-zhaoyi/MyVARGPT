Metadata-Version: 2.4
Name: llamafactory
Version: 0.9.2.dev0
Summary: Easy-to-use LLM fine-tuning framework
Home-page: https://github.com/hiyouga/LLaMA-Factory
Author: hiyouga
Author-email: hiyouga@buaa.edu.cn
License: Apache 2.0 License
Keywords: LLaMA,BLOOM,Falcon,LLM,ChatGPT,transformer,pytorch,deep learning
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch==2.1.0
Requires-Dist: transformers<=4.46.1,>=4.41.2
Requires-Dist: datasets<=3.1.0,>=2.16.0
Requires-Dist: accelerate<=1.0.1,>=0.34.0
Requires-Dist: peft<=0.12.0,>=0.11.1
Requires-Dist: trl<=0.9.6,>=0.8.6
Requires-Dist: tokenizers<0.20.4,>=0.19.0
Requires-Dist: gradio<5.0.0,>=4.0.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: scipy
Requires-Dist: einops
Requires-Dist: sentencepiece
Requires-Dist: tiktoken
Requires-Dist: protobuf
Requires-Dist: uvicorn
Requires-Dist: pydantic
Requires-Dist: fastapi
Requires-Dist: sse-starlette
Requires-Dist: matplotlib>=3.7.0
Requires-Dist: fire
Requires-Dist: packaging
Requires-Dist: pyyaml
Requires-Dist: numpy<2.0.0
Requires-Dist: av
Requires-Dist: tyro<0.9.0
Requires-Dist: deepspeed==0.15.4
Requires-Dist: icecream
Requires-Dist: ipdb
Requires-Dist: timm==0.9.6
Requires-Dist: opencv-python
Requires-Dist: imageio
Provides-Extra: torch
Requires-Dist: torch>=1.13.1; extra == "torch"
Provides-Extra: torch-npu
Requires-Dist: torch==2.1.0; extra == "torch-npu"
Requires-Dist: torch-npu==2.1.0.post3; extra == "torch-npu"
Requires-Dist: decorator; extra == "torch-npu"
Provides-Extra: metrics
Requires-Dist: nltk; extra == "metrics"
Requires-Dist: jieba; extra == "metrics"
Requires-Dist: rouge-chinese; extra == "metrics"
Provides-Extra: deepspeed
Requires-Dist: deepspeed<=0.14.4,>=0.10.0; extra == "deepspeed"
Provides-Extra: liger-kernel
Requires-Dist: liger-kernel; extra == "liger-kernel"
Provides-Extra: bitsandbytes
Requires-Dist: bitsandbytes>=0.39.0; extra == "bitsandbytes"
Provides-Extra: hqq
Requires-Dist: hqq; extra == "hqq"
Provides-Extra: eetq
Requires-Dist: eetq; extra == "eetq"
Provides-Extra: gptq
Requires-Dist: optimum>=1.17.0; extra == "gptq"
Requires-Dist: auto-gptq>=0.5.0; extra == "gptq"
Provides-Extra: awq
Requires-Dist: autoawq; extra == "awq"
Provides-Extra: aqlm
Requires-Dist: aqlm[gpu]>=1.1.0; extra == "aqlm"
Provides-Extra: vllm
Requires-Dist: vllm<0.6.4,>=0.4.3; extra == "vllm"
Provides-Extra: galore
Requires-Dist: galore-torch; extra == "galore"
Provides-Extra: badam
Requires-Dist: badam>=1.2.1; extra == "badam"
Provides-Extra: adam-mini
Requires-Dist: adam-mini; extra == "adam-mini"
Provides-Extra: qwen
Requires-Dist: transformers_stream_generator; extra == "qwen"
Provides-Extra: modelscope
Requires-Dist: modelscope; extra == "modelscope"
Provides-Extra: openmind
Requires-Dist: openmind; extra == "openmind"
Provides-Extra: dev
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary


### Training
You can use the following command to training vis SFT:
```bash
bash run_scripts/run_vargpt_qwen2_1_1_sft.sh
```

NOTE:  The demo and configuration of the data are completely consistent with [LLaMAFactory](https://github.com/hiyouga/LLaMA-Factory). You can freely configure, modify the model architecture, or use any training strategy supported by LLaMA Factory for training.

### Inference
You can use the following command to perform batch image generation inference:
```bash
bash run_scripts/run_eval_vargpt_v1_1.sh
```
The task of batch image editing can be achieved through the following commands:
```bash
bash run_scripts/run_eval_vargpt_v1_1_edit.sh
```
Note:  You need to create and specify the path for image generation in the bash script.

